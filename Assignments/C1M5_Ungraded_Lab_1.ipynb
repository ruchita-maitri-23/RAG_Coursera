{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31276fc2-6669-4aaf-baf5-6e3bfd00d36e",
   "metadata": {},
   "source": [
    "# Ungraded Lab - Tracing a RAG system\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the ungraded lab on tracing and evaluating a RAG system using Weaviate and Phoenix! In this interactive session, you will learn how to effectively use telemetry to trace and troubleshoot a RAG system. You'll get to understand and work with key concepts, including spans, traces, and chains, which are essential in monitoring and improving system performance.\n",
    "\n",
    "In this ungraded lab, you will:\n",
    "\n",
    "- Understand how to set up and use telemetry to monitor your RAG system.\n",
    "- Learn about traces and spans.\n",
    "- Explore traces to see the complete path and interactions within your system processes.\n",
    "- Use the [Phoenix Arize](https://phoenix.arize.com/) tool for visualizing and analyzing telemetry data.\n",
    "- See a small RAG pipeline in action using Phoenix and Weaviate.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d709d-88d4-45eb-9653-8823a6eb3bd5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h4 style=\"color:black; font-weight:bold;\">USING THE TABLE OF CONTENTS</h4>\n",
    "JupyterLab provides an easy way for you to navigate through your assignment. It's located under the Table of Contents tab, found in the left panel, as shown in the picture below.\n",
    "\n",
    "![TOC Location](images/toc.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329bbdf",
   "metadata": {},
   "source": [
    "\n",
    "# Table of Contents\n",
    "- [ 1 - Introduction](#1)\n",
    "  - [ 1.1 Importing necessary libraries](#1-1)\n",
    "- [ 2 - Quick Introduction on Telemetry](#2)\n",
    "  - [ 2.1 Spans](#2-1)\n",
    "- [ 3 - Telemetry Using Phoenix](#3)\n",
    "  - [ 3.1 Launching Phoenix App](#3-1)\n",
    "  - [ 3.2 Preparing the telemetry](#3-2)\n",
    "  - [ 3.3 Working the Pipeline](#3-3)\n",
    "  - [ 3.4 Chains](#3-4)\n",
    "  - [ 3.5 Using the UI to analyze the traces](#3-5)\n",
    "- [ 4 - Tracing and Evaluation with Weaviate](#4)\n",
    "  - [ 4.1 Configuring the tracer](#4-1)\n",
    "  - [ 4.2 Preparing the Weaviate client and collection](#4-2)\n",
    "  - [ 4.3 The Retriever](#4-3)\n",
    "  - [ 4.4 LLM call with `openai` library](#4-4)\n",
    "- [ 5 - Evaluating a RAG system](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a989bf8-820e-413d-a667-8904418c8598",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1 - Introduction\n",
    "\n",
    "---\n",
    "In the context of RAG systems, telemetry is key for monitoring and optimizing performance. By collecting and transmitting data on the system's operations, such as spans (individual steps) and traces (full workflows), telemetry provides a way to watch how the system retrieves, processes, and generates information. This visibility helps identify bottlenecks and diagnose issues, improving system efficiency.\n",
    "\n",
    "<a id='1-1'></a>\n",
    "### 1.1 Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d1486e-9ca4-4eb4-906f-9e1eb9748b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d8f33-1d31-4280-b7c4-f6075b516092",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2 - Quick Introduction on Telemetry\n",
    "---\n",
    "<a id='2-1'></a>\n",
    "### 2.1 Spans\n",
    "\n",
    "In telemetry, a span represents a single operation or task within your system. It's like a snapshot of a specific action, recording when it starts and ends. Spans also include details like what the task is doing and any important events that occur. By tracking spans, you can see how long operations take and spot any issues, helping you understand and improve your system's performance.\n",
    "\n",
    "Let's see an example of how to setup a simple tracer using [OpenTelemetry](https://opentelemetry.io/) - this tool is also used by Phoenix.\n",
    "\n",
    "Note an error reading \"Overriding of current TracerProvider is not allowed\" is generated by the following cell but will not affect the functionality of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3962fb-3d65-4a04-9186-7de0c9fe46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a resource with attributes that describe your application\n",
    "# Here, we're setting the service name to identify what is being traced\n",
    "resource = Resource(attributes={\n",
    "    \"service.name\": \"Test Service\"\n",
    "})\n",
    "\n",
    "# Set up the tracer provider that will manage and provide tracers\n",
    "# 'TracerProvider' is initialized with the resource we just defined\n",
    "trace.set_tracer_provider(TracerProvider(resource=resource))\n",
    "\n",
    "# Create a console exporter to output spans to the console for demonstration purposes\n",
    "# In a real-world scenario, you might use an OTLP exporter to send spans to a tracing system\n",
    "console_exporter = ConsoleSpanExporter()\n",
    "\n",
    "# Set up a span processor to handle the spans\n",
    "# SimpleSpanProcessor sends each span to the exporter as soon as it is finished\n",
    "span_processor = SimpleSpanProcessor(console_exporter)\n",
    "\n",
    "# Add the span processor to the tracer provider to start processing spans immediately\n",
    "trace.get_tracer_provider().add_span_processor(span_processor)\n",
    "\n",
    "# Obtain a tracer for the current module to create and manage spans\n",
    "tracer = trace.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6ce09-5613-4e69-a0d7-fa75b67ed66d",
   "metadata": {},
   "source": [
    "#### 2.1.1 A Toy Retrieve Function\n",
    "\n",
    "This is a basic function designed to illustrate how to set up tracing using spans for a document retrieval operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adba18e-a910-419e-b08f-2cf51030997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, fail=False):\n",
    "    # Start a span to trace the retrieval process\n",
    "    with tracer.start_as_current_span(\"retrieving_documents\") as span:\n",
    "        # Log the event of starting retrieval\n",
    "        span.add_event(\"Starting retrieve\")\n",
    "        # Record the input query as an attribute for visibility\n",
    "        span.set_attribute(\"input.query\", query)\n",
    "        try:\n",
    "            # Simulate a retrieval failure if 'fail' is True\n",
    "            if fail:\n",
    "                raise ValueError(f\"Retrieve failed for query: {query}\")\n",
    "\n",
    "            # Simulated list of retrieved documents\n",
    "            retrieved_docs = ['retrieved doc1', 'retrieved doc2', 'retrieved doc3']\n",
    "            # Record details about each retrieved document\n",
    "            for i, doc in enumerate(retrieved_docs):\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.id\", i)\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.content\", doc)\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", f\"Metadata for document {i}\")\n",
    "        except Exception as e:\n",
    "            # If an exception occurs, log and set the span status to indicate an error\n",
    "            span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            span.set_attribute(\"error.type\", type(e).__name__)\n",
    "            span.set_attribute(\"error.message\", str(e))\n",
    "            # Reraise the exception for handling by the caller\n",
    "            raise\n",
    "\n",
    "        # Mark the span as successful if no error was raised\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "        return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc847e9-71ef-4676-8e11-4b37e9323097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"retrieving_documents\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x1f36ddc8835f4ab3ce9a1330dd94999f\",\n",
      "        \"span_id\": \"0x00928798b6539174\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2026-02-08T22:14:24.347631Z\",\n",
      "    \"end_time\": \"2026-02-08T22:14:24.347718Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"input.query\": \"Test\",\n",
      "        \"retrieval.documents.0.document.id\": 0,\n",
      "        \"retrieval.documents.0.document.content\": \"retrieved doc1\",\n",
      "        \"retrieval.documents.0.document.metadata\": \"Metadata for document 0\",\n",
      "        \"retrieval.documents.1.document.id\": 1,\n",
      "        \"retrieval.documents.1.document.content\": \"retrieved doc2\",\n",
      "        \"retrieval.documents.1.document.metadata\": \"Metadata for document 1\",\n",
      "        \"retrieval.documents.2.document.id\": 2,\n",
      "        \"retrieval.documents.2.document.content\": \"retrieved doc3\",\n",
      "        \"retrieval.documents.2.document.metadata\": \"Metadata for document 2\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"Starting retrieve\",\n",
      "            \"timestamp\": \"2026-02-08T22:14:24.347663Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['retrieved doc1', 'retrieved doc2', 'retrieved doc3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tracer is configured to show the span in the output\n",
    "retrieve(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc11cca-98c4-4535-a6eb-31ee7b5b8af3",
   "metadata": {},
   "source": [
    "## 2.2 Traces\n",
    "---\n",
    "A trace is a collection of spans that represent the journey of a request or transaction as it moves through various components in your system. It is a set of spans that are related to one task.\n",
    "\n",
    "Now let's complete a toy rag pipeline to see what a trace would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff5babb5-5f93-4a6c-8699-2dff7eb30ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_documents(retrieved_docs):\n",
    "    # Start a span to trace the formatting of documents\n",
    "    with tracer.start_as_current_span(\"call_format_documents\") as span:\n",
    "        # Log the event for initiating document formatting\n",
    "        span.add_event(\"Calling format_documents\")\n",
    "        # Record the number of documents being formatted\n",
    "        span.set_attribute(\"input.documents_count\", len(retrieved_docs))\n",
    "\n",
    "        t = ''\n",
    "        for i, doc in enumerate(retrieved_docs):\n",
    "            t += f'Retrieved doc: {doc}\\n'\n",
    "            # Log an event for each processed document\n",
    "            span.add_event(f\"processed document {i}\", {\"document.content\": doc})\n",
    "\n",
    "        # Mark the span as successful after formatting documents\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "    return t\n",
    "\n",
    "def augment_prompt(query, formatted_documents):\n",
    "    # Start a span to trace the prompt augmentation process\n",
    "    with tracer.start_as_current_span(\"augment_prompt\") as span:\n",
    "        # Log the event for the beginning of prompt augmentation\n",
    "        span.add_event(\"Starting prompt augmentation\")\n",
    "        # Record input details such as the query and document length\n",
    "        span.set_attribute(\"input.query\", query)\n",
    "        span.set_attribute(\"input.formatted_documents_length\", len(formatted_documents))\n",
    "\n",
    "        # Create a prompt that combines the query and formatted documents\n",
    "        PROMPT = f\"Answer the query: {query}.\\nRelevant documents:\\n{formatted_documents}\"\n",
    "\n",
    "        # Mark the span as successful\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "    return PROMPT\n",
    "\n",
    "def generate(prompt):\n",
    "    # Start a span to trace the text generation based on the prompt\n",
    "    with tracer.start_as_current_span(\"generate\") as span:\n",
    "        # Log the event for starting text generation\n",
    "        span.add_event(\"Starting text generation\")\n",
    "        # Record the prompt being used for generation\n",
    "        span.set_attribute(\"input.prompt\", prompt)\n",
    "\n",
    "        # Simulate the text generation process\n",
    "        generated_text = f\"Generated text for prompt {prompt}\"\n",
    "\n",
    "        # Mark the span as successful after text generation\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "    return generated_text\n",
    "\n",
    "def rag_pipeline(query, fail = False):\n",
    "    # Start a span to trace the entire RAG pipeline process\n",
    "    with tracer.start_as_current_span(\"rag_pipeline\") as span:\n",
    "        try:\n",
    "            # Step 1: Retrieve documents based on the query\n",
    "            retrieved_docs = retrieve(query, fail = fail)\n",
    "            # Step 2: Format the retrieved documents\n",
    "            formatted_docs = format_documents(retrieved_docs)\n",
    "            # Step 3: Augment the query with relevant documents to form a prompt\n",
    "            prompt = augment_prompt(query, formatted_docs)\n",
    "            # Step 4: Generate a response from the augmented prompt\n",
    "            generated_response = generate(prompt)\n",
    "\n",
    "            # Mark the span as successful when all steps are completed\n",
    "            span.set_status(Status(StatusCode.OK))\n",
    "            return generated_response\n",
    "        except Exception as e:\n",
    "            # If any step raises an exception, set the span status to error\n",
    "            span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            # Reraise the exception for external handling\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2871d0d-65b3-4728-b1f3-d8402b66ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"retrieving_documents\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xe6922f53f8a0218dd2c9d9482d66528c\",\n",
      "        \"span_id\": \"0x9b0e8d9b67101ba4\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x4b429845e775e640\",\n",
      "    \"start_time\": \"2026-02-08T22:18:18.738897Z\",\n",
      "    \"end_time\": \"2026-02-08T22:18:18.738963Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"input.query\": \"This is a test query\",\n",
      "        \"retrieval.documents.0.document.id\": 0,\n",
      "        \"retrieval.documents.0.document.content\": \"retrieved doc1\",\n",
      "        \"retrieval.documents.0.document.metadata\": \"Metadata for document 0\",\n",
      "        \"retrieval.documents.1.document.id\": 1,\n",
      "        \"retrieval.documents.1.document.content\": \"retrieved doc2\",\n",
      "        \"retrieval.documents.1.document.metadata\": \"Metadata for document 1\",\n",
      "        \"retrieval.documents.2.document.id\": 2,\n",
      "        \"retrieval.documents.2.document.content\": \"retrieved doc3\",\n",
      "        \"retrieval.documents.2.document.metadata\": \"Metadata for document 2\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"Starting retrieve\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.738911Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"call_format_documents\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xe6922f53f8a0218dd2c9d9482d66528c\",\n",
      "        \"span_id\": \"0xe8a3172d9eb1d1ae\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x4b429845e775e640\",\n",
      "    \"start_time\": \"2026-02-08T22:18:18.740439Z\",\n",
      "    \"end_time\": \"2026-02-08T22:18:18.740498Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"input.documents_count\": 3\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"Calling format_documents\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.740455Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"processed document 0\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.740473Z\",\n",
      "            \"attributes\": {\n",
      "                \"document.content\": \"retrieved doc1\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"processed document 1\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.740481Z\",\n",
      "            \"attributes\": {\n",
      "                \"document.content\": \"retrieved doc2\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"processed document 2\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.740488Z\",\n",
      "            \"attributes\": {\n",
      "                \"document.content\": \"retrieved doc3\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"augment_prompt\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xe6922f53f8a0218dd2c9d9482d66528c\",\n",
      "        \"span_id\": \"0x251e5e5bfa1b977c\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x4b429845e775e640\",\n",
      "    \"start_time\": \"2026-02-08T22:18:18.741467Z\",\n",
      "    \"end_time\": \"2026-02-08T22:18:18.741501Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"input.query\": \"This is a test query\",\n",
      "        \"input.formatted_documents_length\": 90\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"Starting prompt augmentation\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.741480Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"generate\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xe6922f53f8a0218dd2c9d9482d66528c\",\n",
      "        \"span_id\": \"0x7b31d12f26a6a67b\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x4b429845e775e640\",\n",
      "    \"start_time\": \"2026-02-08T22:18:18.742218Z\",\n",
      "    \"end_time\": \"2026-02-08T22:18:18.742248Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"input.prompt\": \"Answer the query: This is a test query.\\nRelevant documents:\\nRetrieved doc: retrieved doc1\\nRetrieved doc: retrieved doc2\\nRetrieved doc: retrieved doc3\\n\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"Starting text generation\",\n",
      "            \"timestamp\": \"2026-02-08T22:18:18.742232Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"rag_pipeline\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xe6922f53f8a0218dd2c9d9482d66528c\",\n",
      "        \"span_id\": \"0x4b429845e775e640\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2026-02-08T22:18:18.738832Z\",\n",
      "    \"end_time\": \"2026-02-08T22:18:18.742952Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"OK\"\n",
      "    },\n",
      "    \"attributes\": {},\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Trace example 1\n",
    "response = rag_pipeline(\"This is a test query\", fail = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5b24b7-13c8-475d-b73c-847f8eb69ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"retrieving_documents\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x76a90645e2ea26dc38bcea3586d54656\",\n",
      "        \"span_id\": \"0x8f0de246d860780d\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x8dcc6ad16553b2bb\",\n",
      "    \"start_time\": \"2026-02-08T22:19:48.810306Z\",\n",
      "    \"end_time\": \"2026-02-08T22:19:48.813210Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"ERROR\",\n",
      "        \"description\": \"ValueError: Retrieve failed for query: This is a test query\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"input.query\": \"This is a test query\",\n",
      "        \"error.type\": \"ValueError\",\n",
      "        \"error.message\": \"Retrieve failed for query: This is a test query\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"Starting retrieve\",\n",
      "            \"timestamp\": \"2026-02-08T22:19:48.810319Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"exception\",\n",
      "            \"timestamp\": \"2026-02-08T22:19:48.813189Z\",\n",
      "            \"attributes\": {\n",
      "                \"exception.type\": \"ValueError\",\n",
      "                \"exception.message\": \"Retrieve failed for query: This is a test query\",\n",
      "                \"exception.stacktrace\": \"Traceback (most recent call last):\\n  File \\\"/usr/local/lib/python3.10/dist-packages/opentelemetry/trace/__init__.py\\\", line 589, in use_span\\n    yield span\\n  File \\\"/usr/local/lib/python3.10/dist-packages/opentelemetry/sdk/trace/__init__.py\\\", line 1105, in start_as_current_span\\n    yield span\\n  File \\\"/tmp/ipykernel_19/3967606908.py\\\", line 11, in retrieve\\n    raise ValueError(f\\\"Retrieve failed for query: {query}\\\")\\nValueError: Retrieve failed for query: This is a test query\\n\",\n",
      "                \"exception.escaped\": \"False\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"rag_pipeline\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x76a90645e2ea26dc38bcea3586d54656\",\n",
      "        \"span_id\": \"0x8dcc6ad16553b2bb\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2026-02-08T22:19:48.810255Z\",\n",
      "    \"end_time\": \"2026-02-08T22:19:48.814156Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"ERROR\",\n",
      "        \"description\": \"ValueError: Retrieve failed for query: This is a test query\"\n",
      "    },\n",
      "    \"attributes\": {},\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"exception\",\n",
      "            \"timestamp\": \"2026-02-08T22:19:48.814138Z\",\n",
      "            \"attributes\": {\n",
      "                \"exception.type\": \"ValueError\",\n",
      "                \"exception.message\": \"Retrieve failed for query: This is a test query\",\n",
      "                \"exception.stacktrace\": \"Traceback (most recent call last):\\n  File \\\"/usr/local/lib/python3.10/dist-packages/opentelemetry/trace/__init__.py\\\", line 589, in use_span\\n    yield span\\n  File \\\"/usr/local/lib/python3.10/dist-packages/opentelemetry/sdk/trace/__init__.py\\\", line 1105, in start_as_current_span\\n    yield span\\n  File \\\"/tmp/ipykernel_19/4008694445.py\\\", line 55, in rag_pipeline\\n    retrieved_docs = retrieve(query, fail = fail)\\n  File \\\"/tmp/ipykernel_19/3967606908.py\\\", line 11, in retrieve\\n    raise ValueError(f\\\"Retrieve failed for query: {query}\\\")\\nValueError: Retrieve failed for query: This is a test query\\n\",\n",
      "                \"exception.escaped\": \"False\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"service.name\": \"Test Service\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Retrieve failed for query: This is a test query",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Trace example 2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThis is a test query\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(query, fail)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m span:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m# Step 1: Retrieve documents based on the query\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m         retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;66;03m# Step 2: Format the retrieved documents\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         formatted_docs \u001b[38;5;241m=\u001b[39m format_documents(retrieved_docs)\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mretrieve\u001b[0;34m(query, fail)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Simulate a retrieval failure if 'fail' is True\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fail:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieve failed for query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Simulated list of retrieved documents\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     retrieved_docs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrieved doc1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrieved doc2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrieved doc3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Retrieve failed for query: This is a test query"
     ]
    }
   ],
   "source": [
    "# Trace example 2\n",
    "response = rag_pipeline(\"This is a test query\", fail = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719b277-74a8-490e-bada-d5367de72e18",
   "metadata": {},
   "source": [
    "Note: This second trace intentionally failed to show what that might look like in a producton system.\n",
    "\n",
    "As you can see, traces can become quite complex and difficult to read in their raw form, especially in large systems with many interconnected components. This is why tools like Phoenix are important. They help manage and visualize traces, making it easier to analyze the data and diagnose performance issues or bottlenecks efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98412048-7576-4ac7-b5ed-1ad9db6a7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to restart the kernel - necessary as it is not possible to overwrite a tracer in Jupyter Notebook\n",
    "utils.restart_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1dedca-9c1c-4af4-86ba-dc61934feab7",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 - Telemetry Using Phoenix\n",
    "---\n",
    "\n",
    "Phoenix is a powerful tool designed to simplify the management and visualization of telemetry data. It helps you handle complex traces, making it easier to analyze and diagnose issues in your system. With Phoenix, you can monitor your RAG system's performance, identify bottlenecks, and gain insights into how different components of your application interact. In this section, you'll explore how to set up Phoenix and leverage its features to better understand the telemetry data generated by your RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54884ff-462f-4ac5-b548-9ea794eb5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56f570-0335-46d8-86b2-63c6bd9993dd",
   "metadata": {},
   "source": [
    "<a id='3-1'></a>\n",
    "### 3.1 Launching Phoenix App\n",
    "\n",
    "Run the next cell to launch the Phoenix app, which will set up a local server and host a user interface (UI). The default URL for accessing the app is `localhost:6006`, and this will be displayed once you call the application. However, due to the limitations of the Coursera environment, a different link will be provided. You can click this alternate link to navigate to the UI in a new tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb030cfd-bbc7-48ba-b4ed-ef30857e5768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://iburgqpyevpe.labs.coursera.org\u001b[0m\n",
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phoenix.session.session.ThreadSession at 0x7f11d64e3e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.make_url()\n",
    "px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b446e-dc7e-42e3-9bb9-0cfeb0ee0997",
   "metadata": {},
   "source": [
    "You should see something like this:\n",
    "\n",
    "![Phoenix UI Screenshot](images/ui_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661d236-40ba-4f09-b007-fa3dd2bbf097",
   "metadata": {},
   "source": [
    "<a id='3-2'></a>\n",
    "### 3.2 Preparing the telemetry\n",
    "\n",
    "Now you'll configure the telemetry to work with Phoenix. Since Phoenix also uses OpenTelemetry, the setup is very similar to what you've seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7343f2a-2573-4dc1-8594-d7e5b3a8c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: example-rag-pipeline\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://127.0.0.1:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "phoenix_project_name = \"example-rag-pipeline\"\n",
    "\n",
    "# With phoenix, we just need to register to get the tracer provider with the appropriate endpoint.\n",
    "endpoint=\"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider_phoenix = register(project_name=phoenix_project_name, endpoint = endpoint)\n",
    "\n",
    "# Retrieve a tracer for manual instrumentation\n",
    "tracer = tracer_provider_phoenix.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e0263-7886-4f4c-97bb-ebe70bc824a1",
   "metadata": {},
   "source": [
    "<a id='3-3'></a>\n",
    "### 3.3 Using the Pipeline\n",
    "\n",
    "#### 3.3.1 Retrieve\n",
    "\n",
    "This is the same toy retrieve function. The syntax is almost the same, but there are two differences:\n",
    "\n",
    "1. Now there is a `openinference_span_kind`, where you can pass this as a retriever.\n",
    "2. You can now set the input using `span.set_input`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663db7ed-3701-4f23-aeb5-f1064a5b6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, fail=False):\n",
    "    # Start a span to trace the retrieval process. Now we can pass a span kind: retriever\n",
    "    with tracer.start_as_current_span(\"retrieving_documents\", openinference_span_kind = 'retriever') as span:\n",
    "        # Log the event of starting retrieval\n",
    "        span.add_event(\"Starting retrieve\")\n",
    "        # Record the input query as an attribute for visibility\n",
    "        # Phoenix allows you to use span.set_input\n",
    "        span.set_input(query)\n",
    "        try:\n",
    "            # Simulate a retrieval failure if 'fail' is True\n",
    "            if fail:\n",
    "                raise ValueError(f\"Retrieve failed for query: {query}\")\n",
    "\n",
    "            # Simulated list of retrieved documents\n",
    "            retrieved_docs = ['retrieved doc1', 'retrieved doc2', 'retrieved doc3']\n",
    "            # Record details about each retrieved document\n",
    "            for i, doc in enumerate(retrieved_docs):\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.id\", i)\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.content\", doc)\n",
    "                span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", f\"Metadata for document {i}\")\n",
    "        except Exception as e:\n",
    "            # If an exception occurs, log and set the span status to indicate an error\n",
    "            span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            span.set_attribute(\"error.type\", type(e).__name__)\n",
    "            span.set_attribute(\"error.message\", str(e))\n",
    "            # Reraise the exception for handling by the caller\n",
    "            raise\n",
    "\n",
    "        # Mark the span as successful if no error was raised\n",
    "        span.set_status(Status(StatusCode.OK))\n",
    "        return retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0b0a7-e150-451e-94a1-323936dd453d",
   "metadata": {},
   "source": [
    "<a id='3-4'></a>\n",
    "### 3.4 Chains\n",
    "\n",
    "A chain is a connection point between different steps in an LLM application. It links together various operations, like starting a request or passing information from a retriever to an LLM call. Chains help keep things organized and simple. \n",
    "\n",
    "#### 3.4.1 The remaining RAG functions\n",
    "\n",
    "These are the same functions you worked before, but now with the *decorator* `@tracer.chain`. You just need to add it before the function you want to be traced and it will be added as a chain! If you want to make a more detailed tracing, then you should proceed as the retriever above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc849e0-9339-4943-ae03-a8b960896bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.chain\n",
    "def format_documents(retrieved_docs):\n",
    "    t = ''\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        t += f'Retrieved doc: {doc}\\n'\n",
    "    return t\n",
    "\n",
    "@tracer.chain\n",
    "def augment_prompt(query, formatted_documents):\n",
    "    \n",
    "    # Create a prompt that combines the query and formatted documents\n",
    "    PROMPT = f\"Answer the query: {query}.\\nRelevant documents:\\n{formatted_documents}\"\n",
    "    return PROMPT\n",
    "\n",
    "@tracer.chain\n",
    "def generate(prompt):\n",
    "    generated_text = f\"Generated text for prompt {prompt}\"\n",
    "    return generated_text\n",
    "\n",
    "@tracer.chain\n",
    "def rag_pipeline(query, fail = False):\n",
    "        # Step 1: Retrieve documents based on the query\n",
    "        retrieved_docs = retrieve(query, fail = fail)\n",
    "        # Step 2: Format the retrieved documents\n",
    "        formatted_docs = format_documents(retrieved_docs)\n",
    "        # Step 3: Augment the query with relevant documents to form a prompt\n",
    "        prompt = augment_prompt(query, formatted_docs)\n",
    "        # Step 4: Generate a response from the augmented prompt\n",
    "        generated_response = generate(prompt)\n",
    "        return generated_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00882f5-0356-4c5c-9886-d74f77e0574b",
   "metadata": {},
   "source": [
    "<a id='3-5'></a>\n",
    "### 3.5 Using the UI to analyze the traces\n",
    "\n",
    "Now let's get to the fun part! Run the following cell to run the same two queries as before. Then let's go to the Phoenix UI to inspect how it is placed there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1574590-634b-4d77-aec1-5213412cd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_pipeline(\"This is a test query\")\n",
    "try:\n",
    "    response = rag_pipeline(\"This is a test query that failed\", fail = True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb7fcf3-db26-477f-b040-3b3e4c7ae918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://iburgqpyevpe.labs.coursera.org\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "utils.make_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e7b2d-e3a3-40dd-81f4-6cc0d7d5d677",
   "metadata": {},
   "source": [
    "You will see something like this, and all the information is shown to you in an organized way.\n",
    "\n",
    "\n",
    "![Phoenix UI Screenshot](images/ui_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc7b70-e97e-46b2-944c-a5adbea1662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's restart the kernel to work with a more complex example!\n",
    "utils.restart_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32022cc-e76c-4103-b817-fda9b3b7d2c9",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4 - Tracing and Evaluation with Weaviate\n",
    "\n",
    "---\n",
    "\n",
    "Now you are familiar with the basics of telemetry with Phoenix, let's work on a more concrete scenario. Let's get our FAQ questions from M4 Assignment and implement a small RAG pipeline to answer an FAQ related question for a clothing store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d0b04e-b13d-429c-8a14-04e018c353fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'flask_app'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "import phoenix as px\n",
    "import flask_app\n",
    "import weaviate\n",
    "import utils\n",
    "import weaviate_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7f1fb5-73cc-4827-8b3c-7036d4b70235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://iburgqpyevpe.labs.coursera.org\u001b[0m\n",
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
     ]
    }
   ],
   "source": [
    "utils.make_url()\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b40798-2c5e-495f-8d63-53cb1f362303",
   "metadata": {},
   "source": [
    "<a id='4-1'></a>\n",
    "### 4.1 Configuring the tracer\n",
    "\n",
    "The setup is the same as before, but now there is a new argument called `auto_instrument`. Passing it as `True` will automatically trace OpenAI compatible LLM calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a029c7-7384-496c-a9b7-6c58559e3da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: example-rag-pipeline-with-weaviate\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://127.0.0.1:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "phoenix_project_name = \"example-rag-pipeline-with-weaviate\"\n",
    "\n",
    "# With phoenix, we just need to register to get the tracer provider with the appropriate endpoint. Providing auto_instrument = True, OpenAI calls are automatically traced\n",
    "# TogetherAI is OpenAI compatible!\n",
    "tracer_provider_phoenix = register(project_name=phoenix_project_name, endpoint=\"http://127.0.0.1:6006/v1/traces\", auto_instrument=True)\n",
    "\n",
    "# Retrieve a tracer for manual instrumentation\n",
    "tracer = tracer_provider_phoenix.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f344cff-cf1e-4caa-9000-56da32e4c448",
   "metadata": {},
   "source": [
    "<a id='4-2'></a>\n",
    "### 4.2 Preparing the Weaviate client and collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c020e36-f6dd-4cbc-8685-dda7c236ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the weaviate client\n",
    "client = weaviate.connect_to_local(port=8079, grpc_port=50050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b14719-536d-42cf-83fb-d28ae75132a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "data = joblib.load(\"faq.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c377e4-3729-46e3-ac44-eb8a5ece250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are your store hours?',\n",
       " 'answer': 'Our online store is open 24/7. Customer service is available from 9:00 AM to 6:00 PM, Monday through Friday.',\n",
       " 'type': 'general information'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's recall the data structure\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30dcc8bd-12a1-435a-b8b6-4398fab922b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the collection\n",
    "collection = client.collections.get(\"Faq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f4580a-878c-4224-b96a-a01e4bacb5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65f111-e617-40a1-8b5d-c0770c482ed2",
   "metadata": {},
   "source": [
    "<a id='4-3'></a>\n",
    "### 4.3 The Retriever\n",
    "\n",
    "Now you'll set up a retriever like you've done before. This time, you'll also add telemetry to track and understand the retrieval process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49aca49-bc51-48d7-87de-412c156178cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query_text, limit=5):\n",
    "    # Start a span for the query\n",
    "    with tracer.start_as_current_span(\n",
    "        \"query_weaviate\", openinference_span_kind=\"retriever\"\n",
    "    ) as span:\n",
    "        # Set the input for the span\n",
    "        span.set_input(query_text)\n",
    "\n",
    "        # Query the collection\n",
    "        collection_name = \"Faq\"\n",
    "        chunks = client.collections.get(collection_name)\n",
    "        results = chunks.query.near_text(query=query_text, limit=limit)\n",
    "\n",
    "        # Set the retrieved documents as attributes on the span\n",
    "        for i, document in enumerate(results.objects):\n",
    "            span.set_attribute(f\"retrieval.documents.{i}.document.id\", str(document.uuid))\n",
    "            span.set_attribute(f\"retrieval.documents.{i}.document.metadata\", str(document.metadata))\n",
    "            span.set_attribute(\n",
    "                f\"retrieval.documents.{i}.document.content\", str(document.properties)\n",
    "            )  \n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a30692c-71b6-45f5-aca6-0d9bbd7238ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and format the retrieved results\n",
    "@tracer.chain \n",
    "def format_context(results):\n",
    "    context = \"\"\n",
    "    for item in results.objects:\n",
    "        properties = item.properties\n",
    "        context += f\"Question: {properties['question']}\\n\"\n",
    "        context += f\"Answer: {properties['answer']}\\n\"\n",
    "    return context\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2dc9993-ec82-41c6-bc29-78344a7fb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt with the retrieved information\n",
    "@tracer.chain\n",
    "def create_prompt(query_text, context):\n",
    "    prompt = f\"\"\"\n",
    "Based on the following information, please answer the FAQ related question: \"{query_text}\"\n",
    "\n",
    "Relevant FAQ (ordered by relevance):\n",
    "{context}\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23f6b4-43d9-4fea-89d4-af5ff2dc12dc",
   "metadata": {},
   "source": [
    "<a id='4-4'></a>\n",
    "### 4.4 LLM call with `openai` library\n",
    "\n",
    "Since Phoenix integrates with OpenAI-like systems, let's use it. Luckily [together.ai](https://www.together.ai/) is OpenAI compatible! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330e60da-2ec0-4116-9227-0e17475de088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from openai import OpenAI, DefaultHttpxClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027eb1df-eeb4-4aee-85cd-c9629c3bd43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transport to bypass SSL verification\n",
    "transport = httpx.HTTPTransport(local_address=\"0.0.0.0\", verify=False)\n",
    "\n",
    "# Create a DefaultHttpxClient instance with the custom transport\n",
    "http_client = DefaultHttpxClient(transport=transport)\n",
    "\n",
    "# You can use any openai compatible endpoint here!\n",
    "llm_client = OpenAI(\n",
    "    api_key = '', # Set any as the proxy running here does not use it. Set the together api key if using the together endpoint\n",
    "    base_url=\"http://proxy.dlai.link/coursera_proxy/together/\", # If using together endpoint, add it here https://api.together.xyz/\n",
    "   http_client=http_client, # ssl bypass to make it work via proxy calls, remove it if running with together.ai endpoint \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79c892d4-69af-462d-9c45-71979ff6cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no need to trace as the auto_instrument was set to true\n",
    "def query_openai(prompt):\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant from a customer support.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b77517-41b5-454b-b719-9666dbf387bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.chain\n",
    "def rag_pipeline(query):\n",
    "    # Execute the query\n",
    "    retrieved_documents = retrieve(query)\n",
    "    context = format_context(retrieved_documents)\n",
    "    \n",
    "    # Create a prompt with the retrieved information\n",
    "    final_prompt = create_prompt(query, context)\n",
    "    \n",
    "    # Execute the OpenAI query\n",
    "    final_answer = query_openai(final_prompt)\n",
    "\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5170232a-4d6b-49e2-8f89-5903aa7e2f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, here's the answer to your question:\n",
      "\n",
      "\"Unfortunately, you cannot get a refund or exchange for another shirt, as sale items are final sale and cannot be returned or exchanged, unless stated otherwise. However, if you purchased the shirt within the 30-day return policy timeframe and it's not a sale item, you may be able to initiate an exchange through our Returns Center.\"\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline(\"Can I get a refund or exchange for another shirt?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff39c3b4-4eb1-4759-998b-4a7332e4c75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, the answer to the FAQ question \"What are your working hours?\" is:\n",
      "\n",
      "Our customer service is available from 9:00 AM to 6:00 PM, Monday through Friday.\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline(\"What are your working hours?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039e85b5-dbd5-4ce1-8569-94334e071a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFOLLOW THIS URL TO OPEN THE UI: http://iburgqpyevpe.labs.coursera.org\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Checkout the traces in the Phoenix UI!\n",
    "utils.make_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48d349-29d4-4350-8659-1d91caedcda3",
   "metadata": {},
   "source": [
    "Keep it up! You finished the ungraded lab on Telemetry with Phoenix!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
